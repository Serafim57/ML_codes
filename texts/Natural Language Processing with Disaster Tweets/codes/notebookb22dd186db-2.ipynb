{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b8b9ad5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-23T18:38:52.137081Z",
     "iopub.status.busy": "2022-06-23T18:38:52.136065Z",
     "iopub.status.idle": "2022-06-23T18:38:52.150225Z",
     "shell.execute_reply": "2022-06-23T18:38:52.149478Z"
    },
    "papermill": {
     "duration": 0.026252,
     "end_time": "2022-06-23T18:38:52.155202",
     "exception": false,
     "start_time": "2022-06-23T18:38:52.128950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nlp-getting-started/sample_submission.csv\n",
      "/kaggle/input/nlp-getting-started/train.csv\n",
      "/kaggle/input/nlp-getting-started/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c21465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-23T18:38:52.166608Z",
     "iopub.status.busy": "2022-06-23T18:38:52.165885Z",
     "iopub.status.idle": "2022-06-23T18:38:54.601948Z",
     "shell.execute_reply": "2022-06-23T18:38:54.600785Z"
    },
    "papermill": {
     "duration": 2.444639,
     "end_time": "2022-06-23T18:38:54.604844",
     "exception": false,
     "start_time": "2022-06-23T18:38:52.160205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost import Pool\n",
    "from gensim.utils import tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cd4c39b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-23T18:38:54.614844Z",
     "iopub.status.busy": "2022-06-23T18:38:54.614399Z",
     "iopub.status.idle": "2022-06-23T18:38:54.626348Z",
     "shell.execute_reply": "2022-06-23T18:38:54.625477Z"
    },
    "papermill": {
     "duration": 0.019715,
     "end_time": "2022-06-23T18:38:54.628760",
     "exception": false,
     "start_time": "2022-06-23T18:38:54.609045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97200f8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-23T18:38:54.638396Z",
     "iopub.status.busy": "2022-06-23T18:38:54.638041Z",
     "iopub.status.idle": "2022-06-23T18:38:54.712476Z",
     "shell.execute_reply": "2022-06-23T18:38:54.711615Z"
    },
    "papermill": {
     "duration": 0.081845,
     "end_time": "2022-06-23T18:38:54.714968",
     "exception": false,
     "start_time": "2022-06-23T18:38:54.633123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../input/nlp-getting-started/test.csv\")\n",
    "train = pd.read_csv(\"../input/nlp-getting-started/train.csv\")\n",
    "submission = pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e55cb0",
   "metadata": {
    "papermill": {
     "duration": 0.003633,
     "end_time": "2022-06-23T18:38:54.722977",
     "exception": false,
     "start_time": "2022-06-23T18:38:54.719344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's make preprocessing and vectorizing texts;\n",
    "We will use TF-IDF and usual LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf69648c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-23T18:38:54.732893Z",
     "iopub.status.busy": "2022-06-23T18:38:54.732155Z",
     "iopub.status.idle": "2022-06-23T18:38:54.743885Z",
     "shell.execute_reply": "2022-06-23T18:38:54.743124Z"
    },
    "papermill": {
     "duration": 0.019317,
     "end_time": "2022-06-23T18:38:54.746185",
     "exception": false,
     "start_time": "2022-06-23T18:38:54.726868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def remove_urls(vTEXT):\n",
    "    vTEXT = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', vTEXT, flags=re.MULTILINE)\n",
    "    return(vTEXT)\n",
    "\n",
    "\n",
    "# def \n",
    "def preprocessing(df):\n",
    "    text_list = list(df['text'])\n",
    "    preprocessed_texts = []\n",
    "    for i in range(len(text_list)):\n",
    "        text_tokenized = remove_urls(text_list[i])\n",
    "        text_tokenized = list(tokenize(text_tokenized, lower = True, deacc = True))\n",
    "#         preprocessed_texts.append(list(text_tokenized))\n",
    "        text_stemmed = [stemmer.stem(w) for w in text_tokenized if w not in stop_words]\n",
    "        text_without_stop_words = [w for w in text_stemmed if w not in stop_words]\n",
    "        preprocessed_texts.append(text_without_stop_words)\n",
    "        \n",
    "    for i in range(len(preprocessed_texts)):\n",
    "        preprocessed_texts[i] = \" \".join(preprocessed_texts[i])\n",
    "    return preprocessed_texts  #возвращает корпус обработанных твитов\n",
    "\n",
    "\n",
    "\n",
    "def model_vect_texts(df):\n",
    "    vectorizer = TfidfVectorizer() #модель для векторизации текстов\n",
    "    preprocessed_texts_for_train = preprocessing(df) #на каком корпусе текстов будем обучать vectorizer\n",
    "    vectorizer.fit(preprocessed_texts_for_train) #обучаем vectorizer\n",
    "    return vectorizer\n",
    "\n",
    "\n",
    "def preprocessing_features(df, vectorizer):\n",
    "    preprocessed_texts = preprocessing(df)\n",
    "\n",
    "    tfidf = vectorizer.transform(preprocessed_texts)\n",
    "#     df_tfidf = pd.DataFrame(tfidf.toarray(), columns = list(vectorizer.get_feature_names()))\n",
    "#     df_tfidf['loc'] = df['location'] #их слишком много, они практичсеки эквивалентны 'id' как и keyword\n",
    "#     df_tfidf = pd.get_dummies(df_tfidf)\n",
    "    \n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0ea2f65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-23T18:38:54.756498Z",
     "iopub.status.busy": "2022-06-23T18:38:54.755832Z",
     "iopub.status.idle": "2022-06-23T18:38:58.223859Z",
     "shell.execute_reply": "2022-06-23T18:38:58.222711Z"
    },
    "papermill": {
     "duration": 3.47618,
     "end_time": "2022-06-23T18:38:58.226631",
     "exception": false,
     "start_time": "2022-06-23T18:38:54.750451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, train['target'])\n",
    "vectorizer_train = model_vect_texts(X_train)\n",
    "X_train = preprocessing_features(X_train, vectorizer_train)\n",
    "X_test = preprocessing_features(X_test, vectorizer_train)\n",
    "# X_train = vectorizer_train.transform(X_train)\n",
    "# X_test = vectorizer_train.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b53c09c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-23T18:38:58.239138Z",
     "iopub.status.busy": "2022-06-23T18:38:58.238707Z",
     "iopub.status.idle": "2022-06-23T18:38:58.577820Z",
     "shell.execute_reply": "2022-06-23T18:38:58.575929Z"
    },
    "papermill": {
     "duration": 0.350316,
     "end_time": "2022-06-23T18:38:58.581681",
     "exception": false,
     "start_time": "2022-06-23T18:38:58.231365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression on train, f1_score: 0.8480072055843279\n",
      "LogisticRegression on test, f1_score: 0.7576158940397351\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "print(f'LogisticRegression on train, f1_score: {f1_score(y_pred_train, y_train)}')\n",
    "print(f'LogisticRegression on test, f1_score: {f1_score(y_pred_test, y_test)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaae7b6",
   "metadata": {
    "papermill": {
     "duration": 0.007081,
     "end_time": "2022-06-23T18:38:58.600058",
     "exception": false,
     "start_time": "2022-06-23T18:38:58.592977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "let's train our model on the final DataFarme:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7589f9a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-23T18:38:58.637663Z",
     "iopub.status.busy": "2022-06-23T18:38:58.636955Z",
     "iopub.status.idle": "2022-06-23T18:39:03.684821Z",
     "shell.execute_reply": "2022-06-23T18:39:03.684000Z"
    },
    "papermill": {
     "duration": 5.066086,
     "end_time": "2022-06-23T18:39:03.687292",
     "exception": false,
     "start_time": "2022-06-23T18:38:58.621206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorizer_final = model_vect_texts(train)\n",
    "y = train['target']\n",
    "train_final = preprocessing_features(train, vectorizer_final)\n",
    "test_final = preprocessing_features(test, vectorizer_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43615ca9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-23T18:39:03.698119Z",
     "iopub.status.busy": "2022-06-23T18:39:03.697550Z",
     "iopub.status.idle": "2022-06-23T18:39:04.243027Z",
     "shell.execute_reply": "2022-06-23T18:39:04.241597Z"
    },
    "papermill": {
     "duration": 0.555052,
     "end_time": "2022-06-23T18:39:04.247078",
     "exception": false,
     "start_time": "2022-06-23T18:39:03.692026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression on train, f1_score: 0.8466688985604286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(train_final, y)\n",
    "y_pred_train_final = model.predict(train_final)\n",
    "y_pred_test_final = model.predict(test_final)\n",
    "print(f'LogisticRegression on train, f1_score: {f1_score(y_pred_train_final, y)}')\n",
    "y_pred_test_final\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23.604455,
   "end_time": "2022-06-23T18:39:05.183822",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-23T18:38:41.579367",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
